{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Like a new bike, taking Keras out for a ride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1) (1000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with white noise\n",
    "\n",
    "data = np.random.random((1000, 1))\n",
    "labels = np.random.random((1000, 1))\n",
    "\n",
    "print(data.shape, labels.shape)\n",
    "dim = data.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "0s - loss: 0.3134 - acc: 0.0000e+00 - mean_squared_error: 0.3134\n",
      "Epoch 2/20\n",
      "0s - loss: 0.1891 - acc: 0.0000e+00 - mean_squared_error: 0.1891\n",
      "Epoch 3/20\n",
      "0s - loss: 0.1175 - acc: 0.0000e+00 - mean_squared_error: 0.1175\n",
      "Epoch 4/20\n",
      "0s - loss: 0.1046 - acc: 0.0000e+00 - mean_squared_error: 0.1046\n",
      "Epoch 5/20\n",
      "0s - loss: 0.0964 - acc: 0.0000e+00 - mean_squared_error: 0.0964\n",
      "Epoch 6/20\n",
      "0s - loss: 0.0899 - acc: 0.0000e+00 - mean_squared_error: 0.0899\n",
      "Epoch 7/20\n",
      "0s - loss: 0.0857 - acc: 0.0000e+00 - mean_squared_error: 0.0857\n",
      "Epoch 8/20\n",
      "0s - loss: 0.0837 - acc: 0.0000e+00 - mean_squared_error: 0.0837\n",
      "Epoch 9/20\n",
      "0s - loss: 0.0832 - acc: 0.0000e+00 - mean_squared_error: 0.0832\n",
      "Epoch 10/20\n",
      "0s - loss: 0.0824 - acc: 0.0000e+00 - mean_squared_error: 0.0824\n",
      "Epoch 11/20\n",
      "0s - loss: 0.0826 - acc: 0.0000e+00 - mean_squared_error: 0.0826\n",
      "Epoch 12/20\n",
      "0s - loss: 0.0826 - acc: 0.0000e+00 - mean_squared_error: 0.0826\n",
      "Epoch 13/20\n",
      "0s - loss: 0.0827 - acc: 0.0000e+00 - mean_squared_error: 0.0827\n",
      "Epoch 14/20\n",
      "0s - loss: 0.0835 - acc: 0.0000e+00 - mean_squared_error: 0.0835\n",
      "Epoch 15/20\n",
      "0s - loss: 0.0824 - acc: 0.0000e+00 - mean_squared_error: 0.0824\n",
      "Epoch 16/20\n",
      "0s - loss: 0.0826 - acc: 0.0000e+00 - mean_squared_error: 0.0826\n",
      "Epoch 17/20\n",
      "0s - loss: 0.0825 - acc: 0.0000e+00 - mean_squared_error: 0.0825\n",
      "Epoch 18/20\n",
      "0s - loss: 0.0824 - acc: 0.0000e+00 - mean_squared_error: 0.0824\n",
      "Epoch 19/20\n",
      "0s - loss: 0.0825 - acc: 0.0000e+00 - mean_squared_error: 0.0825\n",
      "Epoch 20/20\n",
      "0s - loss: 0.0824 - acc: 0.0000e+00 - mean_squared_error: 0.0824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11a656a58>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do an MLP with three hidden layers with 32, 64, and 32 neurons respectively as regression.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(units=64, activation='relu', input_dim=dim))\n",
    "model.add(Dense(units=32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy', 'mse'])\n",
    "model.fit(data, labels, epochs=20, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = np.random.random((1000,1))\n",
    "predictions = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49989019205 0.492355\n",
      "0.082460859043 0.000299429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.082819300081699992"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at means, variances, and MSE\n",
    "\n",
    "print(labels.mean(), predictions.mean())\n",
    "print(labels.var(), predictions.var())\n",
    "((labels - predictions)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.48459384],\n",
       "       [ 0.47159147],\n",
       "       [ 0.52217305],\n",
       "       [ 0.52007473],\n",
       "       [ 0.48030216],\n",
       "       [ 0.47472093],\n",
       "       [ 0.46720454],\n",
       "       [ 0.49479514],\n",
       "       [ 0.47087759],\n",
       "       [ 0.48012063],\n",
       "       [ 0.51041555],\n",
       "       [ 0.47385672],\n",
       "       [ 0.47832862],\n",
       "       [ 0.4746758 ],\n",
       "       [ 0.47800314],\n",
       "       [ 0.47087339],\n",
       "       [ 0.47404283],\n",
       "       [ 0.48061693],\n",
       "       [ 0.47695288],\n",
       "       [ 0.49562374],\n",
       "       [ 0.47685316],\n",
       "       [ 0.49444503],\n",
       "       [ 0.495249  ],\n",
       "       [ 0.52036035],\n",
       "       [ 0.47163796]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As expected, it's best shot is the average value with virtually no variance.\n",
    "\n",
    "predictions[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A usual suspect.\n",
    "\n",
    "import pandas as pd\n",
    "white = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep=';') \n",
    "red = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummies and stack.\n",
    "\n",
    "red['type'] = 1\n",
    "white['type'] = 0\n",
    "wines = red.append(white, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.215307</td>\n",
       "      <td>0.339666</td>\n",
       "      <td>0.318633</td>\n",
       "      <td>5.443235</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>30.525319</td>\n",
       "      <td>115.744574</td>\n",
       "      <td>0.994697</td>\n",
       "      <td>3.218501</td>\n",
       "      <td>0.531268</td>\n",
       "      <td>10.491801</td>\n",
       "      <td>5.818378</td>\n",
       "      <td>0.246114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.296434</td>\n",
       "      <td>0.164636</td>\n",
       "      <td>0.145318</td>\n",
       "      <td>4.757804</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>17.749400</td>\n",
       "      <td>56.521855</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.160787</td>\n",
       "      <td>0.148806</td>\n",
       "      <td>1.192712</td>\n",
       "      <td>0.873255</td>\n",
       "      <td>0.430779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.996990</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    6497.000000       6497.000000  6497.000000     6497.000000   \n",
       "mean        7.215307          0.339666     0.318633        5.443235   \n",
       "std         1.296434          0.164636     0.145318        4.757804   \n",
       "min         3.800000          0.080000     0.000000        0.600000   \n",
       "25%         6.400000          0.230000     0.250000        1.800000   \n",
       "50%         7.000000          0.290000     0.310000        3.000000   \n",
       "75%         7.700000          0.400000     0.390000        8.100000   \n",
       "max        15.900000          1.580000     1.660000       65.800000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  6497.000000          6497.000000           6497.000000  6497.000000   \n",
       "mean      0.056034            30.525319            115.744574     0.994697   \n",
       "std       0.035034            17.749400             56.521855     0.002999   \n",
       "min       0.009000             1.000000              6.000000     0.987110   \n",
       "25%       0.038000            17.000000             77.000000     0.992340   \n",
       "50%       0.047000            29.000000            118.000000     0.994890   \n",
       "75%       0.065000            41.000000            156.000000     0.996990   \n",
       "max       0.611000           289.000000            440.000000     1.038980   \n",
       "\n",
       "                pH    sulphates      alcohol      quality         type  \n",
       "count  6497.000000  6497.000000  6497.000000  6497.000000  6497.000000  \n",
       "mean      3.218501     0.531268    10.491801     5.818378     0.246114  \n",
       "std       0.160787     0.148806     1.192712     0.873255     0.430779  \n",
       "min       2.720000     0.220000     8.000000     3.000000     0.000000  \n",
       "25%       3.110000     0.430000     9.500000     5.000000     0.000000  \n",
       "50%       3.210000     0.510000    10.300000     6.000000     0.000000  \n",
       "75%       3.320000     0.600000    11.300000     6.000000     0.000000  \n",
       "max       4.010000     2.000000    14.900000     9.000000     1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the result.\n",
    "\n",
    "wines.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timothysavage/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n"
     ]
    }
   ],
   "source": [
    "# Use oldspeak to segment the data as numpy arrays, which Keras needs.  (It can't do everything!)  Do train/test split.  \n",
    "# X are features and y is label.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = wines.ix[:, 0:11]\n",
    "y = np.ravel(wines.type)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1492)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.246113590888 0.246153846154 0.24609375\n"
     ]
    }
   ],
   "source": [
    "print(y.mean(), y_test.mean(), y_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing as a commodity.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Keras structure.\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_shape=(11,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 12)                144       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 257\n",
      "Trainable params: 257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Useful summary of network structure, in particular the list of total parameters being estimated.\n",
    "# I can guess where the non-trainable params is going ;).\n",
    "\n",
    "model.output_shape\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4352/4352 [==============================] - 2s - loss: 0.3484 - acc: 0.8594     \n",
      "Epoch 2/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0557 - acc: 0.9899     \n",
      "Epoch 3/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0359 - acc: 0.9933     \n",
      "Epoch 4/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0292 - acc: 0.9945     \n",
      "Epoch 5/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0255 - acc: 0.9952     \n",
      "Epoch 6/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0227 - acc: 0.9959     \n",
      "Epoch 7/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0210 - acc: 0.9956     \n",
      "Epoch 8/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0195 - acc: 0.9963     \n",
      "Epoch 9/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0180 - acc: 0.9972     \n",
      "Epoch 10/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0171 - acc: 0.9972     \n",
      "Epoch 11/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0164 - acc: 0.9972     \n",
      "Epoch 12/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0157 - acc: 0.9975     \n",
      "Epoch 13/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0152 - acc: 0.9975     \n",
      "Epoch 14/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0143 - acc: 0.9975     \n",
      "Epoch 15/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0141 - acc: 0.9975     \n",
      "Epoch 16/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0137 - acc: 0.9970     \n",
      "Epoch 17/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0134 - acc: 0.9972     \n",
      "Epoch 18/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0130 - acc: 0.9977     \n",
      "Epoch 19/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0126 - acc: 0.9972     \n",
      "Epoch 20/20\n",
      "4352/4352 [==============================] - 1s - loss: 0.0123 - acc: 0.9975     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e13b0f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and estimate.\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create predictions as integer-valued numpy arrays.\n",
    "\n",
    "y_pred = model.predict(X_test).round().astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "[1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Look at first five observations.\n",
    "\n",
    "print(y_pred[:5])\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Rate: 0.993939\n"
     ]
    }
   ],
   "source": [
    "# Standard measures of performance.\n",
    "# First the accuracy rate on the test or validation set.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy Rate: %f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[1615    2]\n",
      " [  11  517]]\n"
     ]
    }
   ],
   "source": [
    "# Next the confusion matrix, which shows correct and incorrect classification on the test set.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion matrix:\\n%s' % confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      1617\n",
      "          1       1.00      0.98      0.99       528\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Next a classification report.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Other stuff\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 255, array([5, 0, 4, ..., 5, 6, 8], dtype=uint8))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1], x_train.max(), y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_norm_train = x_train.astype(np.float32)/255\n",
    "y_norm_train = y_train.astype(np.float32)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABcCAYAAAB+6068AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e3829b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels: [5 0 4 1 9]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_digits = 5\n",
    "for i in range(num_digits):\n",
    "    plt.subplot(1, num_digits, i+1)\n",
    "    plt.imshow(x_train[i], cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('Training labels: %s' % (y_train[0:num_digits],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
